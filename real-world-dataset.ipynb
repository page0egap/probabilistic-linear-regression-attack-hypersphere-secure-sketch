{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import sample as sampler\n",
    "import utils\n",
    "import attacker\n",
    "from model import BackBone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_puzzle_local_search_random(new_bs, new_isometric_matrixes, k = 160):\n",
    "    \"\"\"\n",
    "    Behave as linear equation sampler.\n",
    "\n",
    "    generate matrix with row vector from new_isometric_matrixes randomly,\n",
    "    k indicates the number of row vectors to be selected from each isometric matrix, thus the total number of equations is k*len(new_isometric_matrixes)\n",
    "    \"\"\"\n",
    "    sub_matrixes = []\n",
    "    for b, isometric_matrix in zip(new_bs, new_isometric_matrixes):\n",
    "        # get random subset of shape n of indexb\n",
    "        indexbb = np.random.choice(b.shape[0], k, replace=False)\n",
    "        sub_matrixes.append(isometric_matrix[indexbb, :])\n",
    "\n",
    "    return np.concatenate(sub_matrixes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def local_search_each_runtime(dimension, alpha, sub_matrix, disable_flag=False, each_runtime=1000):\n",
    "    \"\"\"\n",
    "    Test local search run time of inner iteration. Return time = time of inner iteration * each_runtime(number of outer iteration).\n",
    "    \"\"\"\n",
    "    times = 0\n",
    "    # time start\n",
    "    start = time.time()\n",
    "    for _ in (pbar:=tqdm(range(each_runtime), disable=disable_flag, leave=True)):\n",
    "        theta = sampler.sample_codeword(dimension, alpha)\n",
    "        flag = False\n",
    "        # Since the inner iteration could early terminate, thus `800` is unreachable\n",
    "        for _ in range(800):\n",
    "            tmpb = sub_matrix @ theta\n",
    "            # get the norm of tmpb\n",
    "            normb = np.linalg.norm(tmpb)\n",
    "            # get the index of tmpb where are not zero and iterate on it\n",
    "            nonzero = np.where(np.abs(theta) > 0.1)[0]\n",
    "            thetab = None\n",
    "            tmp_sub_matrix = sub_matrix.copy()\n",
    "            # set columns in non_zero positions with 10 * np.ones\n",
    "            tmp_sub_matrix[:, nonzero] = 10 * np.ones((sub_matrix.shape[0], len(nonzero)))\n",
    "            for j1 in nonzero:\n",
    "                tmpbb = tmpb - theta[j1] * sub_matrix[:, j1]\n",
    "                # add\n",
    "                tmpbbb = tmp_sub_matrix + tmpbb[:, np.newaxis]\n",
    "                normbbb = np.linalg.norm(tmpbbb, axis=0)\n",
    "                # get min value and index of normbbb\n",
    "                min_index = np.argmin(normbbb)\n",
    "                min_value = normbbb[min_index]\n",
    "                if min_value < normb:\n",
    "                    thetab = theta.copy()\n",
    "                    thetab[j1] = 0\n",
    "                    thetab[min_index] = 1\n",
    "                    normb = min_value\n",
    "                # sub\n",
    "                tmpbbb =  tmpbb[:, np.newaxis] - tmp_sub_matrix\n",
    "                normbbb = np.linalg.norm(tmpbbb, axis=0)\n",
    "                # get min value and index of normbbb\n",
    "                min_index = np.argmin(normbbb)\n",
    "                min_value = normbbb[min_index]\n",
    "                if min_value < normb:\n",
    "                    thetab = theta.copy()\n",
    "                    thetab[j1] = 0\n",
    "                    thetab[min_index] = -1\n",
    "                    normb = min_value\n",
    "            # pbar update\n",
    "            pbar.set_postfix({\"norm\": normb})\n",
    "            if thetab is not None:\n",
    "                theta = thetab\n",
    "                continue\n",
    "            else:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            times += 1\n",
    "        pbar.set_postfix({\"Reach ending times\": times})\n",
    "    end = time.time()\n",
    "    slap_time = end - start\n",
    "    return slap_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path, where your model is\n",
    "model_path = \"models/ms1mv3_arcface_r100_fp16\"\n",
    "model_file = \"backbone.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters, need to revise if using different model\n",
    "# for example, ms1mv3_arcface_r100_fp16 -> \"r100\", \"fp16\": True\n",
    "kwargs = {\"name\": \"r100\", \"dropout\": 0.0, \"fp16\": True, \"num_features\": 512}\n",
    "platform = \"pytorch\"  # pytorch (\"onnx\" is not supported currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = BackBone(\n",
    "    platform=platform, backbone_path=f\"{model_path}/{model_file}\", **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatial data path\n",
    "data_fei_retinaface_path = \"fei_face_dataset\"\n",
    "# data_color_feret_path = \"/mnt/e/Downloads/colorferet/images_retina\"\n",
    "# data_lfw_retinaface_path = \"/mnt/e/Downloads/lfw\"\n",
    "data_fatial_path = data_fei_retinaface_path  # which dataset do you use\n",
    "data_set_estimated_noise_angle = 25  # hyper paramter, need to adjust according to the dataset(should slightly larger than the Noise in the dataset)\n",
    "selected_subset_index = [1, 2, 3]  # fei dataset: [1, 2, 3] => 04, 05, 06\n",
    "# fei dataset: [0, 2, 5] => 03, 05, 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_estimated_error_rate = utils.translate_error_angle_to_error_noise(\n",
    "    data_set_estimated_noise_angle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IronMask and Attack's Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter of codewords\n",
    "dimension = 512\n",
    "alpha = 16\n",
    "k = 300  # the number of sampled linear equations (k, need to justify in paper section 5 according to noise)\n",
    "threshold = 40  # threshold hyper-parameter(\\theta_t, need to justify in paper section 5 according to noise, but generally 40 is enough)\n",
    "use_precompute = True  # since the testing is time-consuming, we could just load the last precomputed results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp/ms1mv3_arcface_r100_fp16'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "# tempdir: where to temporarily store fatial embeddings\n",
    "tempdir = \"tmp/\" + model_path.split(\"/\")[-1].split(\".\")[0]\n",
    "tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from dataset.fatial_dataset import FatialDataset\n",
    "\n",
    "def transform_x(x):\n",
    "    return x * 2 - 1\n",
    "\n",
    "def transform_y(y):\n",
    "    return str(y)\n",
    "\n",
    "fatial_dataset = FatialDataset(data_fatial_path, transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transform_x]), target_transform=transform_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.fatial_dataset_embedding_dict import FatialDataEmbeddingsDict\n",
    "dataset_dict = FatialDataEmbeddingsDict(file_folder=tempdir, data_set=fatial_dataset, file_raw_name=\"labels.pickle\",)\n",
    "dataset_dict.dump_embeddings(backbone_model, 10, num_workers=0) # because of jupyter notebook's multi-threading issue, we set num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Identities: 200\n"
     ]
    }
   ],
   "source": [
    "identity_list = list(dataset_dict.keys())\n",
    "print(\"Number of Identities:\", len(identity_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving original template against IronMask original scheme if sampled matrix is correct\n",
    "\n",
    "ensure the matrix generated by linear equation sampler is \"correct\" as in Definition 4.1 in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ironmask\n",
    "\n",
    "runtimes_vec = []\n",
    "success_times = 0\n",
    "whole_iteration_times = 80000\n",
    "index_list = selected_subset_index  # the index of the images to be used for puzzle solving, need to revise for different subsets\n",
    "error_rate = data_set_estimated_error_rate  # the error rate of the templates, need to revise and estimate if using different datasets and models\n",
    "if not use_precompute:\n",
    "    for each_identity in (pbar := tqdm(identity_list)):\n",
    "        each_isometric_matrixes = []\n",
    "        each_cs = []\n",
    "        for index in index_list:\n",
    "            tmpcs = ironmask.sample_codeword(dimension, alpha)\n",
    "            each_isometric_matrixes.append(\n",
    "                ironmask.generate_secure_sketch(\n",
    "                    dataset_dict[each_identity][index], tmpcs\n",
    "                )\n",
    "            )\n",
    "            each_cs.append(tmpcs)\n",
    "        assume_vector, b, run_times = attacker.solve_puzzle_with_n_matrix_known_places(\n",
    "            each_isometric_matrixes,\n",
    "            each_cs,\n",
    "            dimension,\n",
    "            alpha,\n",
    "            threshold=threshold,\n",
    "            max_rtimes=whole_iteration_times // len(identity_list),\n",
    "            algorithm=\"LSA\",\n",
    "            disable_tqdm=False,\n",
    "            k_each_matrix=k // 2,\n",
    "            error_rate=error_rate * 3.0,\n",
    "            return_runtimes=True,\n",
    "        )\n",
    "        if b is not None and (\n",
    "            np.allclose(b, each_cs[0]) or np.allclose(b, -each_cs[0])\n",
    "        ):\n",
    "            success_times += 1\n",
    "        pbar.set_postfix({\"Success Rate\": success_times / (pbar.n + 1)})\n",
    "        runtimes_vec.append(run_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if not use_precompute:\n",
    "    with open(\"real-world/runtimes_vec_feret.pickle\", \"wb\") as f:\n",
    "        pickle.dump(runtimes_vec, f)\n",
    "    with open(\"real-world/success_times_feret.pickle\", \"wb\") as f:\n",
    "        pickle.dump(success_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 38.50%\n",
      "Average Number of Run Tries(1/(pk * pf)): 815.60\n",
      "P_k * P_f  = 0.0012260951258737918\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from utils import subset_n_a_alpha\n",
    "\n",
    "with open(\"real-world/runtimes_vec_feret.pickle\", \"rb\") as f:\n",
    "    runtimes_vec = pickle.load(f)\n",
    "with open(\"real-world/success_times_feret.pickle\", \"rb\") as f:\n",
    "    success_times = pickle.load(f)\n",
    "\n",
    "print(\"Success Rate: {:.2f}%\".format(success_times / len(identity_list) * 100))\n",
    "print(\n",
    "    \"Average Number of Run Tries(1/(pk * pf)): {:.2f}\".format(\n",
    "        np.sum(runtimes_vec) / success_times\n",
    "    )\n",
    ")\n",
    "\n",
    "pkf = success_times / np.sum(runtimes_vec)\n",
    "print(\"P_k * P_f  = {}\".format(pkf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test lsa solver time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "whole_time = 0\n",
    "tmp_inner = 1\n",
    "tmp_outer = len(identity_list)\n",
    "for each_identity in (pbar := tqdm(identity_list, desc=\"Outer loop\", disable=False)):\n",
    "    each_isometric_matrixes = []\n",
    "    each_cs = []\n",
    "    for index in index_list:\n",
    "        tmpcs = ironmask.sample_codeword(dimension, alpha)\n",
    "        each_isometric_matrixes.append(\n",
    "            ironmask.generate_secure_sketch(dataset_dict[each_identity][index], tmpcs)\n",
    "        )\n",
    "        each_cs.append(tmpcs)\n",
    "    new_isometric_matrixes = [\n",
    "        each_isometric_matrixes[i] @ each_isometric_matrixes[0].T\n",
    "        for i in range(1, len(each_isometric_matrixes))\n",
    "    ]\n",
    "    new_cs = [each_cs[i] for i in range(1, len(each_cs))]\n",
    "    puzzle = generate_puzzle_local_search_random(\n",
    "        new_cs, new_isometric_matrixes, k=k // 2\n",
    "    )\n",
    "    whole_time += local_search_each_runtime(\n",
    "        dimension, alpha, puzzle, disable_flag=True, each_runtime=tmp_inner\n",
    "    )\n",
    "    pbar.set_postfix({\"Whole Time\": whole_time})\n",
    "tk = whole_time / (tmp_outer * tmp_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(t_k) = 271.6527259349823 miliseconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Time(t_k) = {} miliseconds\".format(tk * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.292172969044763\n",
      "Whole Time:\n",
      "* seconds: 17779627.57\n",
      "* minutes: 296327.13\n",
      "* hours: 4938.79\n",
      "* days: 205.78\n",
      "* years: 0.56\n"
     ]
    }
   ],
   "source": [
    "rk = utils.subset_n_a_alpha(dimension, k//2, alpha) * 2\n",
    "print(rk)\n",
    "et = tk / pkf * (2**rk)\n",
    "print(\"Whole Time:\")\n",
    "print(\"* seconds: {:.2f}\".format(et))\n",
    "print(\"* minutes: {:.2f}\".format(et / 60))\n",
    "print(\"* hours: {:.2f}\".format(et / 3600))\n",
    "print(\"* days: {:.2f}\".format(et / 3600 / 24))\n",
    "print(\"* years: {:.2f}\".format(et / 3600 / 24 / 365))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
