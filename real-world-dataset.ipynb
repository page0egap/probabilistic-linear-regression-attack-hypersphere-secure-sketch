{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import sample as sampler\n",
    "import utils\n",
    "import attacker\n",
    "from model import BackBone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path, where your model is \n",
    "model_path = \"/mnt/e/BaiduNet/ms1mv3_arcface_r100_fp16\"\n",
    "# fatial data path(upper diretory)\n",
    "data_fei_retinaface_path = \"/mnt/e/Downloads/FEI/originalimages_retinaface_122\"\n",
    "data_color_feret_path = \"/mnt/e/Downloads/colorferet/images_retina\"\n",
    "data_fatial_path = data_color_feret_path\n",
    "# model parameters, need to revise if using different model\n",
    "# for example, ms1mv3_arcface_r100_fp16 -> \"r100\", \"fp16\": True\n",
    "kwargs = {\"name\": \"r100\", \"dropout\":0.0, \"fp16\": True, \"num_features\": 512}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = BackBone(platform=\"pytorch\", backbone_path=f\"{model_path}/backbone.pth\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/ms1mv3_arcface_r100_fp16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "# tempdir: where to temporarily store fatial embeddings\n",
    "tempdir = '/tmp/' + model_path.split('/')[-1].split('.')[0]\n",
    "tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from dataset.fatial_dataset import FatialDataset\n",
    "\n",
    "fatial_dataset = FatialDataset(data_fatial_path, transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x * 2 - 1]), target_transform=lambda label: str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.fatial_dataset_embedding_dict import FatialDataEmbeddingsDict\n",
    "dataset_dict = FatialDataEmbeddingsDict(file_folder=tempdir, data_set=fatial_dataset, file_raw_name=\"labels.pickle\")\n",
    "dataset_dict.dump_embeddings(backbone_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123\n"
     ]
    }
   ],
   "source": [
    "identity_list = list(dataset_dict.keys())\n",
    "print(len(identity_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated angle between two noisy templates: 27.715342269093377\n"
     ]
    }
   ],
   "source": [
    "# codeword parameters\n",
    "dimension = 512\n",
    "alpha = 16\n",
    "n = 511\n",
    "error_rate = 0.36    # angle(w + noise_1, w + noise_2) \n",
    "                    # approximate 2*arcsin(error_rate * \\sqrt(2) / \\sqrt(1 + error_rate^2) / 2)\n",
    "print(\"Estimated angle between two noisy templates: {}\".format(2 * np.arcsin(error_rate * np.sqrt(2) / np.sqrt(1 + error_rate**2) / 2) * 180 / np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secure sketch true accept rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb922a5fa7764460bb978874af3318e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "identity_list = list(dataset_dict.keys())\n",
    "print(len(identity_list))\n",
    "\n",
    "import ironmask\n",
    "import math\n",
    "success_num = 0\n",
    "whole_num = 0\n",
    "index_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # according to labels.csv, if the sequences is p02, p03, ..., then index of 0 is p02, index of 1 is p03 and etc\n",
    "index_list = [0, 2, 3]\n",
    "for each_identity in tqdm(identity_list):\n",
    "    for index in index_list:\n",
    "        tmpcs = ironmask.sample_codeword(dimension, alpha)\n",
    "        tmpw = dataset_dict[each_identity][index]\n",
    "        # tmpw = sampler._generate_random_unit_vector_nearby(tmpw, math.tan(56.3228 * math.pi / 180))\n",
    "        tmp_sketch = ironmask.generate_secure_sketch(tmpw, tmpcs)\n",
    "        for indexj in index_list:\n",
    "            if index==indexj: continue\n",
    "            tmpw = dataset_dict[each_identity][indexj]\n",
    "            candidate = tmp_sketch @ tmpw\n",
    "            candidate = ironmask.decode_codeword(candidate, dimension, alpha)\n",
    "            if np.allclose(candidate, tmpcs):\n",
    "                success_num += 1\n",
    "            whole_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_num:  6045 \twhole_num:  6738 success rate:  89.7150%\n"
     ]
    }
   ],
   "source": [
    "print(\"success_num: \", success_num, \"\\twhole_num: \", whole_num, \"success rate: \", \"{:.4f}%\".format(success_num / whole_num * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean angle of two templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f1230b85074ad1af96e8e488f00350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.68718703137075\n"
     ]
    }
   ],
   "source": [
    "# generate puzzle\n",
    "import ironmask\n",
    "import itertools\n",
    "# cs = []\n",
    "# isometric_matrixes = []\n",
    "index_list = [0, 2, 3]\n",
    "angles_sum = 0\n",
    "for each_identity in tqdm(identity_list):\n",
    "    # each_isometric_matrixes = []\n",
    "    # each_cs = []\n",
    "    for indexi, indexj in itertools.combinations(index_list, 2):\n",
    "        angles_sum += utils.get_angle_of_two_vectors(dataset_dict[each_identity][indexi], dataset_dict[each_identity][indexj])\n",
    "    # for index in index_list:  # according to labels.csv, if the sequences is p02, p03, ..., then index of 0 is p02, index of 1 is p03 and etc\n",
    "    #     tmpcs = ironmask.sample_codeword(dimension, alpha)\n",
    "    #     tmpw = dataset_dict[each_identity][index]\n",
    "    #     # tmpw = sampler._generate_random_unit_vector_nearby(tmpw, math.tan(56.3228 * math.pi / 180))\n",
    "    #     each_isometric_matrixes.append(ironmask.generate_secure_sketch(dataset_dict[each_identity][index], tmpcs))\n",
    "    #     each_cs.append(tmpcs)\n",
    "    # cs.append(cs)\n",
    "    # isometric_matrixes.append(each_isometric_matrixes)\n",
    "angle_mean = angles_sum / (len(index_list) * (len(index_list) - 1) // 2 * len(identity_list))\n",
    "print(angle_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solving original template if sampled matrix is correct\n",
    "\n",
    "ensure the matrix generated by linear equation sampler is \"correct\" as in Definition 4.1 in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lsa solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes_vec = []\n",
    "success_times = 0\n",
    "whole_iteration_times = 80000\n",
    "for each_identity in (pbar:=tqdm(identity_list)):\n",
    "    each_isometric_matrixes = []\n",
    "    each_cs = []\n",
    "    for index in [0, 2, 3]:\n",
    "        tmpcs = ironmask.sample_codeword(dimension, alpha)\n",
    "        each_isometric_matrixes.append(ironmask.generate_secure_sketch(dataset_dict[each_identity][index], tmpcs))\n",
    "        each_cs.append(tmpcs)\n",
    "    assume_vector, b, run_times = attacker.solve_puzzle_with_n_matrix_known_places(each_isometric_matrixes, each_cs, dimension, alpha,  threshold=49, max_rtimes=whole_iteration_times//len(identity_list), algorithm=\"LSA\", disable_tqdm=False, k_each_matrix=200, error_rate = error_rate * 3.0, return_runtimes = True)\n",
    "    if b is not None and (np.allclose(b, each_cs[0]) or np.allclose(b, -each_cs[0])):\n",
    "        success_times += 1\n",
    "    pbar.set_postfix({\"Success Rate\": success_times / (pbar.n + 1)})\n",
    "    runtimes_vec.append(run_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"runtimes_vec_feret.pickle\", \"wb\") as f:\n",
    "    pickle.dump(runtimes_vec, f)\n",
    "with open(\"success_times_feret.pickle\", \"wb\") as f:\n",
    "    pickle.dump(success_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 7.93%\n",
      "Average Run Times: 67.72\n",
      "854.4831460674159\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from utils import subset_n_a_alpha\n",
    "\n",
    "with open(\"runtimes_vec_feret.pickle\", \"rb\") as f:\n",
    "    runtimes_vec = pickle.load(f)\n",
    "with open(\"success_times_feret.pickle\", \"rb\") as f:\n",
    "    success_times = pickle.load(f)\n",
    "\n",
    "print(\"Success Rate: {:.2f}%\".format(success_times / len(identity_list) * 100))\n",
    "print(\"Average Run Times: {:.2f}\".format(np.mean(runtimes_vec)))\n",
    "print(np.mean(runtimes_vec) * len(identity_list) / success_times)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel-attack-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
